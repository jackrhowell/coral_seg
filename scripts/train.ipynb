{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ed1ead6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from dataset import CoralDataModule\n",
    "from model import CoralSegFormer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91dde183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDATE ME!\n",
    "# Configure paths\n",
    "user = \"linneamw\"\n",
    "dataset_dir = f\"/home/{user}/sadow_koastore/shared/coral_seg/processed_images_real2/\"\n",
    "results_dir = \"../../results/\"\n",
    "\n",
    "# Configure hyperparameters\n",
    "batch_size = 8 \n",
    "epochs = 30\n",
    "split_ratio = 0.8\n",
    "num_workers = 4\n",
    "samples_per_image = 100\n",
    "crop_size = (512, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b586845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning /home/linneamw/sadow_koastore/shared/coral_seg/processed_images_real2/...\n",
      "Found 118 valid image/mask pairs.\n",
      "Training on 94 images.\n",
      "Validating on 24 images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linneamw/anaconda3/envs/coral_seg/lib/python3.10/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize the data module\n",
    "data_module = CoralDataModule(\n",
    "    root_dir=dataset_dir, \n",
    "    batch_size=batch_size, \n",
    "    split_ratio=split_ratio,\n",
    "    num_workers=num_workers,\n",
    "    samples_per_image=samples_per_image,\n",
    "    crop_size=crop_size\n",
    ")\n",
    "\n",
    "data_module.setup() \n",
    "train_loader = data_module.train_dataloader()\n",
    "val_loader = data_module.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cc7547",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linneamw/anaconda3/envs/coral_seg/lib/python3.10/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/home/linneamw/anaconda3/envs/coral_seg/lib/python3.10/site-packages/PIL/Image.py:3452: DecompressionBombWarning: Image size (99307124 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load an example batch to determine input shape\n",
    "example_batch = next(iter(train_loader))\n",
    "input_shape = example_batch['image'].shape[1:]  # Exclude batch dimension\n",
    "\n",
    "print(f\"Input shape: {input_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaa1802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = CoralSegFormer(learning_rate=3e-4)\n",
    "\n",
    "# Callbacks\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    dirpath= results_dir + 'checkpoints',\n",
    "    filename='coral-segformer-{epoch:02d}-{val_loss:.2f}',\n",
    "    save_top_k=2,\n",
    "    mode='min',\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "callbacks = [checkpoint_callback, early_stop_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bd5344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PyTorch Lightning Trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=epochs,\n",
    "    accelerator=\"auto\", # Auto-detects GPU/CPU\n",
    "    devices=1,\n",
    "    callbacks=callbacks,\n",
    "    log_every_n_steps=10\n",
    ")\n",
    "\n",
    "# Train\n",
    "print(\"Starting Training...\")\n",
    "trainer.fit(model, data_module)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coral_seg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
